"use strict";(self.webpackChunknjit_gsa=self.webpackChunknjit_gsa||[]).push([[9201],{3905:function(e,t,n){n.d(t,{Zo:function(){return l},kt:function(){return f}});var r=n(7294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function c(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=r.createContext({}),d=function(e){var t=r.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},l=function(e){var t=d(e.components);return r.createElement(s.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},p=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,s=e.parentName,l=c(e,["components","mdxType","originalType","parentName"]),p=d(n),f=a,m=p["".concat(s,".").concat(f)]||p[f]||u[f]||i;return n?r.createElement(m,o(o({ref:t},l),{},{components:n})):r.createElement(m,o({ref:t},l))}));function f(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=p;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,o[1]=c;for(var d=2;d<i;d++)o[d]=n[d];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}p.displayName="MDXCreateElement"},2150:function(e,t,n){n.r(t),n.d(t,{frontMatter:function(){return c},contentTitle:function(){return s},metadata:function(){return d},toc:function(){return l},default:function(){return p}});var r=n(7462),a=n(3366),i=(n(7294),n(3905)),o=["components"],c={sidebar_position:55},s="054",d={unversionedId:"research-day-2019/054",id:"research-day-2019/054",isDocsHomePage:!1,title:"054",description:"Title:",source:"@site/docs/research-day-2019/054.md",sourceDirName:"research-day-2019",slug:"/research-day-2019/054",permalink:"/docs/research-day-2019/054",version:"current",sidebarPosition:55,frontMatter:{sidebar_position:55},sidebar:"defaultSidebar",previous:{title:"053",permalink:"/docs/research-day-2019/053"},next:{title:"055",permalink:"/docs/research-day-2019/055"}},l=[{value:"Title:",id:"title",children:[]},{value:"Presenter:",id:"presenter",children:[]},{value:"Abstract:",id:"abstract",children:[]},{value:"Author(s):",id:"authors",children:[]},{value:"Funding Acknowledgements:",id:"funding-acknowledgements",children:[]}],u={toc:l};function p(e){var t=e.components,n=(0,a.Z)(e,o);return(0,i.kt)("wrapper",(0,r.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("h1",{id:"054"},"054"),(0,i.kt)("h2",{id:"title"},"Title:"),(0,i.kt)("p",null,"Enhancing Domain Word Embedding via Latent Semantic Imputation"),(0,i.kt)("p",null,(0,i.kt)("strong",{parentName:"p"},"Discipline:")," data mining, representation learning, spectral graph method"),(0,i.kt)("h2",{id:"presenter"},"Presenter:"),(0,i.kt)("p",null,"Shibo Yao"),(0,i.kt)("h2",{id:"abstract"},"Abstract:"),(0,i.kt)("p",null,"We present a novel method named Latent Semantic Imputation (LSI)to transfer external knowledge into semantic space for enhancing word embedding. The method integrates graph theory to extract the latent manifold structure of the entities in the affinity space and leverages non-negative least squares with standard simplex constraints and power iteration method to derive spectral embeddings.It provides an effective and efficient approach to combining entity representations defined in different Euclidean spaces. Specifically,our approach generates and imputes reliable embedding vectors for low-frequency words in the semantic space and benefits down-stream language tasks that depend on word embedding. We conduct comprehensive experiments on a carefully designed classification problem and language modeling and demonstrate the superiority of the enhanced embedding via LSI over several well-known bench-mark embeddings. We also confirm the consistency of the results under different parameter settings of our method."),(0,i.kt)("h2",{id:"authors"},"Author(s):"),(0,i.kt)("p",null,"Shibo Yao; Dantong Yu; Keli Xiao"),(0,i.kt)("h2",{id:"funding-acknowledgements"},"Funding Acknowledgements:"),(0,i.kt)("p",null,"NJIT"))}p.isMDXComponent=!0}}]);